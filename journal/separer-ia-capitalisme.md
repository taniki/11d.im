---
title: séparer l'IA du capitalisme
date: 2023-02-07
---

## disclaimer

Tout d'abord, commençons par une présentation sur la forme.
Ceci est un article de blog qui a surtout pour intention d'organiser ma réflexion sur divers thèmes.
Je transformerai sans doute ce texte en quelque chose de plus documenté avec un travail de références une fois que j'aurai une idée claire sur le dispositif.
C'est donc avant tout un cheminement d'intérêt légèrement rédigé.
Je suppose que les personnes averties économiquement vont trouver ce texte *cringe*, j'apprends cette grille de lecture et essaie de faire sens de cette vision du monde.
Cela peut être intéressant de partager comment les mots-clés s'articulent dans ma tête et comment cela oriente mes lectures.

Il y aura certainement à boire et à manger pour tout le monde, c'est un buffet sans être de la grande cuisine.


## introduction

J'ai ce texte en tête depuis plusieurs jours, mais je profite d'un jour de grève pour le rédiger et le publier.
Ce n'est pas anodin, car, aujourd'hui, je pense que la question de l'intelligence artificielle est principalement une question de travail.
Sans trop creuser, il y a même un lien avec l'objet du mouvement social : la retraite, c.-à-d. la fin du travail.

Le texte ultime n'existera sans doute jamais, cependant je suis assez frustré par la conversation collective sur ChatGPT, OpenAI, l'intelligence artificielle en général et ce que cela signifie sur nos quotidiens.


## science

### modèles de langage

Ce qu'on appelle intelligence artificielle dans ce contexte est des *modèles de langage*.

Dans le prolongement, certains parlent de *general artificial intelligence*.
C'est un terme qui est quelque part utilisé comme un horizon pour la recherche scientifique et une diversion pour ne pas parler des sujets qui fâchent.

Un modèle de langage est grosso modo l'assemblage d'un dispositif d'entrainement qui produit un modèle préentrainé et d'un dispositif d'inférence qui utilise le produit précédent pour calculer une prédiction.
Dans ce contexte, c'est la prédiction sur le texte à venir : de la prose, du code ou des tableaux.
[Attention is all you need](https://arxiv.org/abs/1706.03762).
"Attention" comme dans "attente" ou "attending".


Il n'y a pas de connaissance mis à part par effet de hasard plus ou moins contrôlé.
Comprendre et expliquer sont des taches qui sont en dehors de ce jeu.
Quand on demande à un dispositif comme ChatGPT d'expliquer quelque chose, sa réponse est une structure de texte qui a la forme langagière d'une explication.
C'est un peu comme un mentaliste qui va lire très rapidement des signaux corporels ou autres pour deviner une question qu'il a lui-même posée.
Cette lecture est basée sur la mémorisation et une bibliothèque de codes culturels.

Cette structuration a au moins deux niveaux : le corpus qui confirme ce qui ressemble à une explication ou non dans les conversations passées et le *préfixe* de la requête, dit aussi *prompt*.
Que cela soit ChagGPT ou l'IA de notion, les requêtes faites par les utilisateurs sont précédées par des indications de structure.
Par exemple, quand on demande une liste, une instruction sur la forme d'une liste est ajoutée sans que cela soit visible : c'est un texte avec plusieurs lignes commençant par un signe.
Quand on demande une explication, le préfixe peut être la bonne vieille structure, thèse, antithèse, synthèse, trois paragraphes pour chaque partie, etc.


### émergence

Les modèles de langage ne sont pas aussi simples que cela.
En regardant sous le capot, on peut voir qu'il y a tout un ensemble de composants et de technologie.
Des variations sur le processus d'entrainement et des variations sur les corpus d'entrainement qui produisent des résultats différents, mais similaires.

Dans le domaine des systèmes, j'ai souvent entendu la distinction entre "compliqué" et "complexe".
Mon opinion est que la technicité et les détails des modèles sont de l'autre de la complication.

Cependant, on peut se poser la question de l'illusion de langage.
Est-ce qu'elle a vraiment lieu pour des raisons intrinsèques aux modèles ?
Si oui, est-ce que la taille des modèles a une causalité ?
Ce qui semble fonctionner ce sont les modèles aboutissant à un système nécessitant une mémoire de taille conséquente.
Est-ce qu'il y a donc une ligne de démarcation avec d'un côté des systèmes qui donnent l'impression de discuter avec un système informatique et de l'autre un système qui donne l'illusion d'un *échange conversationnel* ?
On pourrait parler d'émergence, car cette frontière n'inscrit pas une règle en tant que telle, mais délimite un changement qualitatif entre les systèmes.

C'est une question que je trouve intéressante et qui m'intéresse.
Parler d'intelligence artificielle est certainement un abus de langage dans lequel on se laisse aller.
Mais cet usage de l'artifice semble tout de même dire beaucoup sur nos dimensions sociales et culturelles.
Nos modes de cognition et d'apprentissage sont en décalage avec les modes des machines et cela permet de mieux comprendre ce qui nous caractérise.


## capitalisme

Cela étant dit, le débat et la conversation ne concernent pas du tout cet aspect scientifique.
Pour comprendre, ce qui se dit et ce qui se passe, mon opinion est qu'il s'agit avant tout de problématiques du système capitalisme.
Le titre dévoile déjà cet angle de lecture.
Rentrons donc dans le vif du sujet.

David Harvey, dans sa lecture marxiste, caractérise le capitalisme dans une dynamique d'exploitation/exploitant/exploité. D'autres, comme Bourdieu si mes souvenirs sont bons, préfèreront la polarité domination/dominant/dominé.

Cette discussion dépasse largement le cas d'OpenAI.
C'est par contre, je pense, un bon exemple de la transversalité des problématiques qui font que le monde est ce qu'il est aujourd'hui.


### blitzscaling

OpenAI est l'entreprise derrière la famille des modèles GPT.
La promesse de départ était un monde meilleur et une ligne de défense contre les mésusages des intelligences artificielles.
Ces derniers mois cette problématique a complètement disparu et les dirigeants de l'entreprise sont aujourd'hui en quête de profits à défaut de rentabilité.

Pourquoi parle-t-on donc d'OpenAI en ce moment ?
Ce n'est pas pour les avancées techniques, mais par la commercialisation de différents modèles :
DALL-E pour la génération d'images,
ChatGPT pour la génération de conversations,
et Whisper pour la génération d'actes de parole.

Ces modèles sont coûteux à produire et à utiliser.
En dehors des levées de fond vertigineuses, OpenAI est aujourd'hui déficitaire.
Il est temps de ramener de l'argent et donc devenir acteur de l'économie capitaliste.

Il n'est pas étonnant de retrouver Hoffman Reid parmi les investisseurs et intéressés.
Le personnage a théorisé cette pratique de création d'un marché économique, de croissance rapide à perte pour enfin aboutir à un monopole promettant une rente exponentielle.


### compétition

Le discours dominant est que la compétition économique est une bonne chose.
En vrai, c'est un spectacle assez lointain pour le commun des mortels.

Le premier niveau est la confrontation entre Microsoft et Google concernant le monopole de ce dernier sur les moteurs de recherche.
En investissant et en faisant un partenariat avec OpenAI, Microsoft veut essayer de faire monter la valeur de son propre moteur en offrant une meilleure qualité de réponse, une meilleure compréhension des requêtes et de bout en bout une meilleure expérience utilisateur.
Trouver son chemin sur Google n'a jamais été une mince affaire, il faut savoir formuler une recherche avec les bons mots et souvent en anglais.
Cela va avoir pour conséquence d'obliger Google à augmenter le coût des requêtes.
De l'autre Microsoft va également voir les coûts de fonctionnement augmenter, mais avec la meilleure pertinence des résultats, la valeur perçue d'OpenAI va également augmenter et donc l'investissement de Microsoft (1 + 11 milliards USD).

L'intégration des modèles d'OpenAI dans la suite Office de Microsoft va également dans le même sens et souligne la stratégie des premiers.
Se positionner comme plateforme IA et ainsi rendre l'écosystème de l'économie numérique surdépendant à ces produits.
La commercialisation d'une offre payante est donc à mon avis qu'une stratégie de popularisation a contrario d'une stratégie de démocratisation.
L'usage d'une intelligence artificielle ne se fera pas directement, mais par l'intermédiaire d'un service qui voudra augmenter ses fonctionnalités pour maximiser les profits par un abonnement ou bien exploitation de données de comportement.

Les entreprises qui voudront utiliser de l'IA auront alors deux options parmi d'autres : passer par les API d'OpenAI ou alors monter une infrastructure chez Microsoft (ou Google ou Amazon).

### globalisation

Un autre aspect intéressant est la globalisation des services numériques.
OpenAI et surtout Microsoft sont des entreprises américaines, mais dont les clients finaux sont théoriquement partout où il y a Internet.
Cela va de même pour Twitter qui a des employés dans le monde entier pour répondre aux différents localismes.

En renforçant ces produits ou en devenant une dépendance critique pour des d'autres entreprises, on rentre également dans des problématiques de commerce international.
Cela vaut pour l'extraction de capitaux par la taxe de revenus publicitaires autant que par l'exploitation et la fuite des diplômés.

Cela ne va qu'augmenter le débit d'argent qui s'échappe vers les différents montages pour payer moins d'impôts.
Les circuits financiers sont ceux d'entreprises américaines. Les personnes qui s'enrichissent sont quasi exclusivement des ressortissants états-uniens.
Les usagers les plus protégés restent ceux du pays d'origine : les États-Unis.
Dans le même sens, la bonne ou mauvaise santé de ces entreprises ne concerne qu'une fraction du monde.
À t-on déjà vu un service baisser le tarif de ses abonnements à la mesure de ses profits ?

À défaut de mieux comprendre le monde, il me semble important de garder en tête qu'il s'agit avant tout d'un spectacle situé, englobant par sa faculté à englober, mais dont la plupart du public n'a pas de moyen direct d'action.

Avec l'impérialisme vient aussi une forme de colonialisme.
Concernant spécifiquement OpenAI, je me pose la question du mimétisme des formes d'argumentation et d'expression.
Cela sera aussi vrai pour le jour où Word proposera de la génération de texte.
Est-ce qu'on va voir la continuation d'une sorte d'aplatissement du monde et des formes culturelles ?


### technologie et création de valeur

Et l'innovation dans tout ça ?
Théoriquement, c'est le moteur de l'économie.
Les avancées techniques permettent un meilleur rendement qui augmente le profit.

Avec ChatGPT, OpenAI n'a pas innové, n'a rien apporté de nouveau.
Le T et le G de GPT sont des technologies issues des travaux et investissements de Google.
Pourtant, on pourrait s'attendre à un travail d'ouverture et de transparence de la part d'OpenAI.
Depuis GPT3, ce n'est pas le cas.
Tout est derrière une API tarifée au volume des prompts.

Une lecture qui me semble intéressante est celle du [capitalisme de plateforme](/highlights/srnicek-platformcapitalism/).
On en revient à la machinerie de Microsoft qui multipliera la valeur de ses produits par leur juxtaposition, des effets de clôture et de l'exploitation des données d'usage.
La somme devenant supérieure aux parties.


### croissance et travail

Finalement, dans le cycle d'exploitation, on en revient à une question de travail.
Pour assurer leur croissance, un produit comme ChatGPT permet de faire baisser les coûts de production.
Cette réduction peut avoir deux conséquences négatives : la baisse des salaires/effectifs et la baisse de qualité des produits transformés.
Quand le but est de produire des contenus pour ramener du trafic du moteur de recherche, le travail d'information devient secondaire.
L'information est une sorte de bonus autour de la machine publicitaire.
Que se passera-t-il quand les médias ne seront plus une source profitable d'exposition publicitaire ?
Qu'ils arrêteront de chercher à l'être ?

> After all, publishers like these no longer have audiences in real sense; what they have instead is traffic — a huge stream of drive-by readers, delivered by search engines, that they can monetize primarily by getting them to make attributable purchases.
>
> [How Google's Bard AI could shake up search](https://www.platformer.news/p/how-googles-bard-ai-could-shake-up)

Cette différence peut être transformée en capital supplémentaire à accumuler.

La tautologie "nous vivons dans la société dans laquelle nous vivons" fait qu'on ne peut pas non plus espérer grand-chose d'autre de l'exploitation de cette technologie.

Est-ce que les IA produites seraient différentes si ce n'est pas pour assurer une croissance marginale de certaines entreprises ?
Est-ce que ce n'est pas une pièce en plus dans le mythe de la croissance infinie ?

Les travaux autour de [Bloom](https://huggingface.co/bigscience/bloom) vont dans ce sens.
C'est un modèle à la fois ouvert et dont l'usage est à la fois distribué et repartagé.

Je ne pense même pas qu'il faille aller jusqu'à adopter un discours anti-capitaliste.
Il y a encore quelques années, il était question de la taille des modèles pour simplement les rendre utilisables sur un téléphone "intelligent".
On assiste aujourd'hui à un retour du cloud, autrement dit l'ordinateur de quelqu'un d'autre en location.
Ce qui pose au final la dépendance et la résilience des pratiques de travail.
Sera-t-on encore capable d'écrire sans Internet ? Quel Internet est-il viable ?

Question qui n'est pas si triviale, personnellement, et bien avant copilot, je pense que je ne saurai pas faire grand chose sans l'accès à un moteur de recherche qui me renvoie vers stackoverflow ou la documentation des différentes bibliothèques logicielles que j'utilise au quotidien.
Le travail informatique (et du code) est toujours un travail reposant sur un partage précédent.


## créativité et travail de l'esprit

Je tenais à présenter également une vision alternative, voire positive, qui existe également ailleurs.
Au-delà d'une question scientifique et d'une lecture des enjeux économiques, j'aimerai poser la question de faire les choses différemment ou différentes en dépolarisant les conversations.

Dans le meilleur des mondes, l'IA devrait nous amener à améliorer notre qualité de vie et à moins travailler.
C'est un discours qui pourrait être tenu pour toutes les technologies, les discours sur la technique.
Faire plus et mieux en travailler moins.

Maintenant que tout cela est dit, je continue à être fasciné par les usages possibles.
Je suis bien conscient que je m'exprime d'un point de vue privilégié.
La valeur de mon travail est multipliée par ces usages.
Il n'y a pas encore question de remplacement.

J'ai demandé à plusieurs services de m'aider à écrire ce texte et c'était loin d'être satisfaisant.
Par contre, les correcteurs orthographiques et l'usage d'outils de résumé automatique sur ce texte en lui-même aident à son amélioration.
J'ai un peu plus de temps pour réfléchir et j'en perds moins à me soucier des fautes par exemple.

Quand j'utilise copilot, l'assistant à la programmation de Microsoft, je gagne du temps parce que je sais où est l'erreur dans le code qu'il me propose.

C'est très certainement une forme d'*accélarationnisme* de ma part.
J'espère réfléchir plus et augmenter une certaine production en travaillant moins.
La curiosité pour ces objets techniques est-elle une bonne chose ?

C'est un pari que font plus ou moins intentionnellement les personnes qui sont en mesure de comprendre et de faire ces outils.

