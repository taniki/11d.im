---
title: apprendre à parler aux machines
date: 2023-01-09
---

L'intelligence artificielle connait ces dernières années connaît un 
essort assez spétaculaire.
Le dernier phénomène est la famille GPT, pour [Generative Pre-Trained 
Transformer][gpt].
Je vous la fait courte, c'est un algorithme qui est très performant pour 
générer un texte en inférant ce qui le précède, le prompt.
Il y a l'illusion de répondre à une question ou une intention mais c'est 
plutôt comme quand on commence une phrase sans savoir comment la finir 
et qu'on laisse l'interlocuteur le faire.
Le dispositif fonctionne d'autant mieux qu'il a pu apprendre quels mots 
sont habituellement proche les uns des autres mais aussi à quoi peuvent 
ressembler des phrases, des paragraphes etc.

Bien que principalement marketé par OpenAI, GPT n'est rien de moins ou 
de plus que des technologies Google qui ont été arrosées par l'argent de 
Microsoft. Le coût d'entrainment de GPT-3 peut coûter jusqu'à [12 
millions de dollars][3].

Ce [guide] est un ensemble de ressources permettant de comprendre les 
bases du *prompt engineering*.
Sorte de mentalisme inversé où on essaie de faire dire à la machine ce 
que l'on veut en lui donnant à voir ou du nudge.
C'est une lecture passionnante.

En lui donnant les bons exemples, il est ainsi possible de [réaliser des 
additions][1].
Si on se contente de parler simplement, la machine va faire une 
prédiction plus ou moins hasardeuse et se tromper.

Dans les premiers romans d'Asimov sur les robots, on suit les aventures 
de [Susan Calvin][2], une robopsychologue, dont le métier commence 
exactement comme cela.

[guide]: https://github.com/dair-ai/Prompt-Engineering-Guide
[gpt]: https://en.wikipedia.org/wiki/GPT-3
[1]: https://arxiv.org/abs/2201.11903
[2]: https://fr.wikipedia.org/wiki/Susan_Calvin
[3]: 
https://venturebeat.com/ai/ai-machine-learning-openai-gpt-3-size-isnt-everything/

