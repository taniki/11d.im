---
title: bricoler chez soi en machine learning
date: 2023-01-12
---

Alors pourquoi [construire une machine][1] pour faire de la data science 
? Et qu'est-ce que j'ai appris au passage ?

Les cartes graphiques prévues pour jouer à des jeux vidéo sont aussi utilisables pour faire du machine learning ou du mining.
Cette dernière raison explique un prix ridicule sur les modèles haut de gamme depuis un certain temps.
Avec la crise récente de la bulle crypto, les prix sont revenus à des prix moins démentiels.

Spécifiquement sur le marché de l'occasion, avec un peu de patience, il est possible de trouver des NVIDIA RTX 3080 TI FE à 650e et des NVIDIA RTX 3090 FE à 750e.
Ces modèles ont respectivement 12 giga de RAM et 24 giga de RAM.
Pour faire des inférences avec [la version à 1,3 milliards de paramètres de GPT-3 de NVIDIA][2], il est recommandé d'avoir au moins 10 giga de RAM.
Jouable et dans les clous donc.

J'avais hésité à ne faire que l'acquisition d'une carte graphique, on dit aussi GPU, pour l'utiliser en externe, eGPU, mais mon ordi n'avait même pas de port thunderbolt.

Ce que j'avais largement sous-estimé, c'est assez bêtement le disque dur.
J'avais auparavant un disque dur de 256 go et je pensais qu'1 to allait être l'opulence.
N'importe quel modèle pré-entraîné se compte en centaines de go.
La version maximaliste de [BLOOM][3], l'alternative Open Science de GPT, dépasse le to.

Personnellement, faire du deep learning n'est pas vraiment une priorité et il me semble que l'état de l'art en inférence causale n'est pas encore aussi gourmant.

J'ai bien envie d'essayer trois choses.

[Polars][4] est une alternative à Pandas qui s'inspire de son langage.
Ce dernier est par défaut mono-thread, pour résumer il va faire ses calculs une ligne à la fois.
Polars au contraire cherche à exploiter au maximum le nombre de threads du processeur.
Cela ne va pas linéairement plus vite mais le gain de performance est quand même plus que notable.

Alternativement, [cuDF][5] permet de [cuisiner les données][6] à la manière de pandas mais en utilisant le GPU.

Dans un autre registre, [BlazingSQL][7] permet de faire du traitement de données avec un langage SQL en utilisant également le GPU.
Le projet a l'air un peu mort donc c'est plus par curiosité qu'autre chose.

Il y a sans doute également pas mal de choses à essayer en visualisation, en cartographie et en [analyse géospatiale][8].

Bon voilà, j'ai une belle cuisine avec des ustensiles qui brillent.
Il n'y a plus qu'à.

[1]: https://11d.im/yo/20230108215139/
[2]: https://developer.nvidia.com/blog/deploying-a-1-3b-gpt-3-model-with-nvidia-nemo-megatron/
[3]: https://huggingface.co/bigscience/bloom
[4]: https://www.pola.rs/
[5]: https://github.com/rapidsai/cudf
[6]: https://11d.im/yo/20221213214327/
[7]: https://github.com/BlazingDB/blazingsql
[8]: https://docs.rapids.ai/api/cuspatial/stable/
