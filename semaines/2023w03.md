---
title: 2023w03
date: 2023-01-20
---

Histoire de débuter l'écriture de bilans hebdomadaires, je vais commencer par un récapitulatif de ce que j'ai vu, lu, joué, bref, consommé cette dernière semaine.
Mon intention est surtout d'avoir un regard réflexif sur ce qui a attiré mon attention et par la suite où est-ce que j'ai moi-même fait attention.

C'est une première itération que j'ai compilée à la main.
Peut-être que cela vaudra le coup d'automatiser quelques passages et d'ajouter des informations comme le temps de lecture.
Relire et faire un travail de re-passage a également ses vertus.

## lire


J'ai continué et sur le point de finir *A Wall of Storms* de Ken Liu.  
C'est une lecture que je regrette et que j'aimerai développer dans une note à part.

J'ai commencé la lecture *Mostly Harmless Econometrics* de Joshua Angrist et Jörn-Steffen Pischke.  
C'est ardu, mais c'est ce que je cherchais.
Cela me donne à voir mes outils statistiques sous un nouvel éclairage où je me trouve dorénavant naïf.

J'ai lu d'une traite *Chiffre* d'Olivier Martin.  
C'était à la fois très synthétique et très juste.
Cela me conforte dans ma posture entre statistiques et critique sociale.

## écouter

- [Food Is Art. So Why Do People Treat It Differently?](https://www.theringer.com/2023/1/12/23552563/food-is-art-so-why-do-people-treat-it-differently) - The Dave Chang Show

## lire le web

En vrac, ce qui a attiré mon attention sur le web ces 7 derniers jours.
Surtout les contenus textuels, car je ne sais pas vraiment quoi faire de ce que je consomme sur sur YouTube.

Il y a tout de même un certain pattern d'actualité sur les coûts des *Large Language Model*.


- [De L’Ecole Alsacienne À Saint-Jean-De-Passy, Ces Lycées Parisiens Privés Très Bien Dotés Par Rapport Au Public](https://www.lemonde.fr/les-decodeurs/article/2023/01/18/de-l-ecole-alsacienne-a-saint-jean-de-passy-ces-lycees-parisiens-prives-tres-bien-dotes-par-rapport-au-public_6158385_4355770.html)
- [ChatGPT and Generative AI Look Like Tech's Next Boom. They Could Be the Next Bubble](https://www.businessinsider.com/chatgtp-and-generative-ai-could-form-techs-next-big-bubble-2023-1?r=US&IR=T)
- [Alphabet's Google Margins Could Be at Risk From ChatGPT - Morgan Stanley](https://www.investing.com/news/stock-market-news/alphabets-google-margins-could-be-at-risk-from-chatgpt--morgan-stanley-432SI-2977425)
- [How Much Should You Invest in Influencer Marketing? - Issue 128](https://substack.com/inbox/post/97416536)
- [OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic](https://time.com/6247678/openai-chatgpt-kenya-workers/)
- [Software-Defined Assets](https://docs.dagster.io/concepts/assets/software-defined-assets#loading-asset-values-outside-of-dagster-runs)
- [CNET Is Reviewing the Accuracy of All Its AI-Written Articles After Multiple Major Corrections](https://gizmodo.com/cnet-ai-chatgpt-news-robot-1849996151)
- [The Shit Show](https://furbo.org/2023/01/15/the-shit-show/)
- [AI Art Tools Stable Diffusion and Midjourney Targeted With Copyright Lawsuit](https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart)
- [The 25 Best Amazon Prime Shows Right Now](https://www.wired.com/story/best-shows-amazon-prime/)
- [How to (Finally) Break That Bad Habit](https://www.wired.com/story/how-to-break-bad-habits/)
- [A Note About My Article on Goitein With Respect to Zettelkasten Output Processes](https://boffosocko.com/2023/01/14/a-note-about-my-article-on-goitein-with-respect-to-zettelkasten-output-processes/)
- [Playacting Genius: The Performative Logic of Reasoning From First Principles](https://www.baldurbjarnason.com/2022/first-principles/)
- [Stop Feeding the Hype and Start Resisting](https://irisvanrooijcogsci.com/2023/01/14/stop-feeding-the-hype-and-start-resisting/)
- [When Did the Anthropocene Actually Begin?](https://www.wired.com/story/when-did-the-anthropocene-actually-begin/)

La même chose, mais avec une citation choisie et parfois un commentaire.
Cette partie mériterait sans doute d'être produite au fil de l'eau.
Pas certain que cette version en bloc soit vraiment productive.


[De L’Ecole Alsacienne À Saint-Jean-De-Passy, Ces Lycées Parisiens Privés Très Bien Dotés Par Rapport Au Public](https://www.lemonde.fr/les-decodeurs/article/2023/01/18/de-l-ecole-alsacienne-a-saint-jean-de-passy-ces-lycees-parisiens-prives-tres-bien-dotes-par-rapport-au-public_6158385_4355770.html)

> Interrogé, le recteur de Paris, Christophe Kerrero, reste évasif sur les écarts de dotations entre lycées généraux et sur le fait que des lycées privés sélectifs et socialement privilégiés se trouvent mieux lotis que des établissements publics qui le sont moins, à rebours de la logique de distribution des moyens et de la politique en faveur de la mixité menée dans le public. Mais il certifie que les deux enveloppes budgétaires sont « strictement paritaires », et que la raison est à chercher du côté de la spécificité de gestion de l’enseignement privé.

---

[ChatGPT and Generative AI Look Like Tech's Next Boom. They Could Be the Next Bubble](https://www.businessinsider.com/chatgtp-and-generative-ai-could-form-techs-next-big-bubble-2023-1?r=US&IR=T)

> In a research note, Morgan Stanley analysts compared ChatGPT's cost-per-query to Google's cost-per-search. At an estimated average of $0.02 per query, they estimated that OpenAI's costs are about seven times higher than Google's $0.003 per query.
> 
> The difference, the analysts note, is the significance of "the compute intensity of ChatGPT's natural language models."
> 
> They added that even if OpenAI has access to the lowest-priced tiers for Azure, the Microsoft cloud service that hosts ChatGPT, queries made on the AI chatbot would still be four times more expensive than an average Google search.

J'aimerais bien lire la note en première main, mais impossible de savoir comment y accéder.

---

[Alphabet's Google Margins Could Be at Risk From ChatGPT - Morgan Stanley](https://www.investing.com/news/stock-market-news/alphabets-google-margins-could-be-at-risk-from-chatgpt--morgan-stanley-432SI-2977425)

> Morgan Stanley estimates ChatGPT's cost per query is $0.02 on average, with the compute intensity of ChatGPT's natural language models that store, recall, analyze, and compile large amounts of text into answers in a natural language format being significant. Meanwhile, their analysis means they estimate that ChatGPT's average cost per query ranges anywhere from $0.004-$0.044.

Il est intéressant d'avoir à la fois la perspective du coût de la production du modèle préentrainé et le coût d'usage pour les inférences.

---

[How Much Should You Invest in Influencer Marketing? - Issue 128](https://substack.com/inbox/post/97416536)

---

[OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic](https://time.com/6247678/openai-chatgpt-kenya-workers/)

> The data labelers employed by Sama on behalf of OpenAI were paid a take-home wage of between around $1.32 and $2 per hour depending on seniority and performance. For this story, TIME reviewed hundreds of pages of internal Sama and OpenAI documents, including workers’ payslips, and interviewed four Sama employees who worked on the project. All the employees spoke on condition of anonymity out of concern for their livelihoods.

---

[Software-Defined Assets](https://docs.dagster.io/concepts/assets/software-defined-assets#loading-asset-values-outside-of-dagster-runs)

Au travail, nous avons choisi Dagster pour l'orchestration de nos traitements de données.
L'articulation avec le travail d'analyse ne me semble encore ni vraiment évidente ni intuitif.

---

[CNET Is Reviewing the Accuracy of All Its AI-Written Articles After Multiple Major Corrections](https://gizmodo.com/cnet-ai-chatgpt-news-robot-1849996151)

> Usually, when an editor approaches an article (particularly an explainer as basic as “What is Compound Interest”), it’s safe to assume that the writer has done their best to provide accurate information. But with AI, there is no intent, only the product. An editor evaluating an AI-generated text cannot assume anything, and instead has to take an exacting, critical eye to every phrase, world, and punctuation mark. It’s a different type of task from editing a person, and one people might not be well-equipped for, considering the degree of complete, unfailing attention it must take and the high volume CNET seems to be aiming for with its ChatGPT-produced stories.

---

[The Shit Show](https://furbo.org/2023/01/15/the-shit-show/)

> Like my mom, the API has been declining for awhile. Endpoints were removed, new features were unavailable to third parties, and rate limiting restricted what we could do. And like my mom, we struggled on and did the best we could, trying to stay upbeat about it all.

Le drama twitter continue. Les API ont été débranchées pour les applications iPhone et Android qui ont pourtant été un vecteur d'acquisition de nouveaux publics.
Il est intéressant que cela soit une décision plutôt qu'un incident technique.
Pas encore la fin de la partie, mais on s'en rapproche.

---

[AI Art Tools Stable Diffusion and Midjourney Targeted With Copyright Lawsuit](https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart)

> Butterick and Saveri are currently suing Microsoft, GitHub, and OpenAI in a similar case involving the AI programming model CoPilot, which is trained on lines of code collected from the web.

---

[The 25 Best Amazon Prime Shows Right Now](https://www.wired.com/story/best-shows-amazon-prime/)

> Whether the ongoing story nails the landing remains to be seen, but for sheer high fantasy spectacle, there’s nothing better at the moment.

J'étais assez étonné du titre connaissant la mauvaise qualité du catalogue d'amazon et du four qu'est *The Ring of Power*.
J'ai essayé d'apprécier cette série et pourtant j'ai abandonné au bout de quelques épisodes.

---

[How to (Finally) Break That Bad Habit](https://www.wired.com/story/how-to-break-bad-habits/)

> If your chosen way to try and break your habit isn’t working, maybe it’s time to try something else. Another thing to keep in mind is that “for some specific behaviors, like quitting smoking, multiple attempts is actually a good thing,” Wood says. “Because most people who ultimately quit have to keep trying until they figure out the right thing that will work for them.”

Je pourrai me dire que lire ce genre d'article est une mauvaise habitude.
Des fois cela m'aide, mais je me retrouve assez régulièrement à partager mes réflexions sur ce qui marche à des proches.
Cela me semble alors toujours un peu hors sol sur le moment.

---

[A Note About My Article on Goitein With Respect to Zettelkasten Output Processes](https://boffosocko.com/2023/01/14/a-note-about-my-article-on-goitein-with-respect-to-zettelkasten-output-processes/)

> While the majority of the article is broadly straightforward stringing together of facts, one of the interesting insights for me was connecting a broader range of idiosyncratic note taking and writing practices together across time and space to the idea of statistical mechanics. This is slowly adding to a broader thesis I’m developing about the evolving life of these knowledge practices over time. I can’t wait to see what develops from this next.

---

[Playacting Genius: The Performative Logic of Reasoning From First Principles](https://www.baldurbjarnason.com/2022/first-principles/)

> The history of almost every non-trivial field is full of dead ends and bad ideas that were impossible to predict before the fact. Genuinely reasoning about the field from first principles will regularly lead you into one of these dead ends.
>
> This is why that annoying coworker alternates between interesting observation and inane idiocies. Their speedrun through various fields sometimes leads them into interesting corners and sometimes into dead ends. Your problem is that you don’t know whether or not their interesting observations are dead ends that you simply don’t recognise because it’s in a field unfamiliar to you.

---

[Stop Feeding the Hype and Start Resisting](https://irisvanrooijcogsci.com/2023/01/14/stop-feeding-the-hype-and-start-resisting/)

> Academics should be a voice of reason; uphold values such as scientific integrity, critical reflection, and public responsibility. Especially in this moment in history, it is vital that we provide our students with the critical thinking skills that will allow them to recognise misleading claims made by tech companies and understand the limits and risks of hyped and harmful technology that is made mainstream at a dazzling speed and on a frightening scale.

Une lecture assez importante de ces dernières semaines.
Non pas seulement sur les dernières modes en "intelligence artificielle", mais pour les technologies en général. Il faut savoir revenir au temps long.

---

[When Did the Anthropocene Actually Begin?](https://www.wired.com/story/when-did-the-anthropocene-actually-begin/)

> Defining the Anthropocene is vital, researchers say, because it brings together all the impacts of humans on the world, thereby providing a platform for holistic understanding and, hopefully, action to repair the damage. From a scientific perspective, a precise definition is essential for a clear basis for debate.
